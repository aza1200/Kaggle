{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from konlpy.tag import Mecab\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.model_selection import train_test_split\n",
    "# torch==1.10.0\n",
    "# torchtext==0.11.2\n",
    "# legacy 사용해서 코드 진행하기 위해 버전 맞춰줬음!\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext.legacy import data, datasets\n",
    "from torchtext.legacy.data import TabularDataset\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 모델 구현\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
    "        super(Net, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.lstm = nn.LSTM(embed_dim, self.hidden_dim,\n",
    "                          num_layers=self.n_layers,\n",
    "                          batch_first=True)\n",
    "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x, (ho,co) = self.lstm(x)\n",
    "        h_t = x[:,-1,:] # 모든 문장을 거쳐서 나온 가장 마지막 단어의 출력 값\n",
    "        self.dropout(h_t)\n",
    "        logit = self.out(h_t)  # (배치 크기, 은닉 상태의 크기) -> (배치 크기, 출력층의 크기)\n",
    "        return logit\n",
    "\n",
    "    def _init_state(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "vocab_size = 26696\n",
    "n_classes = 7\n",
    "DEVICE = torch.device('cpu')\n",
    "model = Net(4, 128, vocab_size , 128, n_classes, 0.2).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (embed): Embedding(26696, 128)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (lstm): LSTM(128, 128, num_layers=4, batch_first=True)\n",
       "  (out): Linear(in_features=128, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(4, 128, vocab_size , 128, n_classes, 0.2).to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"./txtclassification.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Okt()\n",
    "# 3개의 필드 정의\n",
    "ID = data.Field(sequential = False,\n",
    "                use_vocab = False) # 실제 사용은 하지 않을 예정\n",
    "\n",
    "TEXT = data.Field(sequential=True,\n",
    "                  use_vocab=True,\n",
    "                  tokenize=tokenizer.morphs, # 토크나이저로는 Mecab 사용.\n",
    "                  lower=True,\n",
    "                  batch_first=True,\n",
    "                  fix_length=30)\n",
    "\n",
    "LABEL = data.Field(sequential=False,\n",
    "                   use_vocab=False,\n",
    "                   is_target=True)\n",
    "# sequential : 시퀀스 데이터 여부. (True가 기본값)\n",
    "# use_vocab : 단어 집합을 만들 것인지 여부. (True가 기본값)\n",
    "# tokenize : 어떤 토큰화 함수를 사용할 것인지 지정. (string.split이 기본값)\n",
    "# lower : 영어 데이터를 전부 소문자화한다. (False가 기본값)\n",
    "# batch_first : 미니 배치 차원을 맨 앞으로 하여 데이터를 불러올 것인지 여부. (False가 기본값)\n",
    "# is_target : 레이블 데이터 여부. (False가 기본값)\n",
    "# fix_length : 최대 허용 길이. 이 길이에 맞춰서 패딩 작업(Padding)이 진행된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = TabularDataset.splits(\n",
    "        path='.', train='train_new.csv', validation='valid_new.csv', test='test_new.csv', format='csv',\n",
    "        fields=[('ID',ID),('text', TEXT), ('label', LABEL)], skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 26695\n",
      "클래스의 개수 : 7\n"
     ]
    }
   ],
   "source": [
    "#각각의 단어집합 생성, 2번 이상 등장한 단어들 사용\n",
    "TEXT.build_vocab(train_data, min_freq=2)\n",
    "LABEL.build_vocab(train_data)\n",
    "vocab_size = len(TEXT.vocab)\n",
    "n_classes = 7\n",
    "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
    "print('클래스의 개수 : {}'.format(n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토치텍스트는 모든 텍스트를 배치 처리하는 것을 지원하고, 단어를 인덱스 번호로 대체하는 BucketIterator를 제공한다.\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
    "        (train_data, valid_data, test_data), batch_size=BATCH_SIZE,\n",
    "        shuffle=True, repeat=False, sort=False) #sorted False 추가!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_iter):\n",
    "    \"\"\"학습된 모델로 정답 파일 예측\"\"\"\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    pred = []\n",
    "    for batch in test_iter:\n",
    "        x = batch.text.to(DEVICE)\n",
    "        logit = model(x)\n",
    "        pred=torch.argmax(logit,axis= 1).tolist()\n",
    "        preds.extend(pred)\n",
    "    return preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13491"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = predict(model,test_iter)\n",
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1598, 1: 1604, 2: 1728, 3: 1871, 4: 792, 5: 891, 6: 5007}\n"
     ]
    }
   ],
   "source": [
    "test_value_counts = {\n",
    "    0:0, 1:0, 2:0,3:0,4:0,5:0,6:0\n",
    "}\n",
    "\n",
    "for tmp in pred:\n",
    "    test_value_counts[tmp] +=1\n",
    "    \n",
    "print(test_value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  label\n",
       "0   0      0\n",
       "1   1      0\n",
       "2   2      0\n",
       "3   3      0\n",
       "4   4      0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.read_csv('./output/all_zero_submission.csv')\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['label']= pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  label\n",
       "0   0      0\n",
       "1   1      2\n",
       "2   2      6\n",
       "3   3      2\n",
       "4   4      0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('./lora.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter):\n",
    "    real_answer_list = []\n",
    "    my_predict_list = []\n",
    "    \"\"\"검증 데이터셋 평가\"\"\"\n",
    "    model.eval()\n",
    "    batch_cor, total_loss = 0, 0\n",
    "\n",
    "    for batch in val_iter:\n",
    "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "        y= torch.tensor(y,dtype = torch.long,device =DEVICE)\n",
    "        logit = model(x)\n",
    "        real_answer_list.extend(y.data)\n",
    "        loss = F.cross_entropy(logit, y)\n",
    "        my_predict_list.extend(logit.max(1)[1])\n",
    "        total_loss += loss.item()\n",
    "        batch_cor += (logit.max(1)[1] == y.data).sum() \n",
    "\n",
    "    size = len(val_iter.dataset)\n",
    "    avg_loss = total_loss / size \n",
    "    avg_accuracy = 100.0 * batch_cor / size\n",
    "\n",
    "\n",
    "    return avg_loss, avg_accuracy,real_answer_list,my_predict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27396\\1864612902.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y= torch.tensor(y,dtype = torch.long,device =DEVICE)\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy, valid_answer_list, my_predict_list= evaluate(model, val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13180\n",
      "13180\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_answer_list))\n",
    "print(len(my_predict_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_answer_list = [tmp.item() for tmp in valid_answer_list]\n",
    "my_predict_list = [tmp.item() for tmp in my_predict_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014964916187371035 tensor(69.5068)\n"
     ]
    }
   ],
   "source": [
    "print(val_loss, val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def calculate_f1_score(y_true, y_pred, average=True):\n",
    "    \"\"\"각 라벨별 F1 score를 계산하고, 평균을 구해 반환\"\"\"\n",
    "    f1_scores = []\n",
    "    \n",
    "    y_true = np.array(y_true) # list를 numpy array로 변환\n",
    "    y_pred = np.array(y_pred) # list를 numpy array로 변환\n",
    "    \n",
    "    for label in range(7):\n",
    "        y_true_label = (y_true == label).astype(int)\n",
    "        y_pred_label = (y_pred == label).astype(int)\n",
    "        f1 = f1_score(y_true_label, y_pred_label)\n",
    "        f1_scores.append(f1)\n",
    "    if average:\n",
    "        return sum(f1_scores) / len(f1_scores)\n",
    "    else:\n",
    "        return f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.663194577030277"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_f1_score(valid_answer_list,my_predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
