{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input directory path : ./input/\n",
      "ord_3\n",
      "['a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o']\n",
      "ord_4\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R'\n",
      " 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z']\n",
      "ord_5\n",
      "['AP' 'Ai' 'Aj' 'BA' 'BE' 'Bb' 'Bd' 'Bn' 'CL' 'CM' 'CU' 'CZ' 'Cl' 'DH'\n",
      " 'DN' 'Dc' 'Dx' 'Ed' 'Eg' 'Er' 'FI' 'Fd' 'Fo' 'GD' 'GJ' 'Gb' 'Gx' 'Hj'\n",
      " 'IK' 'Id' 'JX' 'Jc' 'Jf' 'Jt' 'KR' 'KZ' 'Kf' 'Kq' 'LE' 'MC' 'MO' 'MV'\n",
      " 'Mf' 'Ml' 'Mx' 'NV' 'Nf' 'Nk' 'OR' 'Ob' 'Os' 'PA' 'PQ' 'PZ' 'Ps' 'QM'\n",
      " 'Qb' 'Qh' 'Qo' 'RG' 'RL' 'RP' 'Rm' 'Ry' 'SB' 'Sc' 'TR' 'TZ' 'To' 'UO'\n",
      " 'Uk' 'Uu' 'Vf' 'Vx' 'WE' 'Wc' 'Wv' 'XI' 'Xh' 'Xi' 'YC' 'Yb' 'Ye' 'ZR'\n",
      " 'ZS' 'Zc' 'Zq' 'aF' 'aM' 'aO' 'aP' 'ac' 'av' 'bF' 'bJ' 'be' 'cA' 'cG'\n",
      " 'cW' 'ck' 'cp' 'dB' 'dE' 'dN' 'dO' 'dP' 'dQ' 'dZ' 'dh' 'eG' 'eQ' 'eb'\n",
      " 'eg' 'ek' 'ex' 'fO' 'fh' 'gJ' 'gM' 'hL' 'hT' 'hh' 'hp' 'iT' 'ih' 'jS'\n",
      " 'jV' 'je' 'jp' 'kC' 'kE' 'kK' 'kL' 'kU' 'kW' 'ke' 'kr' 'kw' 'lF' 'lL'\n",
      " 'll' 'lx' 'mb' 'mc' 'mm' 'nX' 'nh' 'oC' 'oG' 'oH' 'oK' 'od' 'on' 'pa'\n",
      " 'ps' 'qA' 'qJ' 'qK' 'qP' 'qX' 'qo' 'qv' 'qw' 'rZ' 'ri' 'rp' 'sD' 'sV'\n",
      " 'sY' 'sn' 'su' 'tM' 'tP' 'tv' 'uJ' 'uS' 'ud' 'us' 'ut' 'ux' 'uy' 'vK'\n",
      " 'vq' 'vy' 'wu' 'wy' 'xP' 'xy' 'yN' 'yY' 'yc' 'zU']\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "import pandas as pd\n",
    "# 데이터 경로\n",
    "# 캐글 ↓제출경로\n",
    "data_path = '/kaggle/input/cat-in-the-dat/'\n",
    "if not path.exists(data_path):\n",
    "    data_path = './input/'\n",
    "print(f'input directory path : {data_path}')\n",
    "\n",
    "\n",
    "train = pd.read_csv(data_path + 'train.csv', index_col='id')\n",
    "test = pd.read_csv(data_path + 'test.csv', index_col='id')\n",
    "submission = pd.read_csv(data_path + 'sample_submission.csv', index_col='id')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 합치기\n",
    "all_data = pd.concat([train, test])\n",
    "all_data = all_data.drop('target', axis=1) # 타깃 값 제거\n",
    "\n",
    "all_data['bin_3'] = all_data['bin_3'].map({'F':0, 'T':1})\n",
    "all_data['bin_4'] = all_data['bin_4'].map({'N':0, 'Y':1})\n",
    "\n",
    "ord1dict = {'Novice':0, 'Contributor':1, \n",
    "            'Expert':2, 'Master':3, 'Grandmaster':4}\n",
    "ord2dict = {'Freezing':0, 'Cold':1, 'Warm':2, \n",
    "            'Hot':3, 'Boiling Hot':4, 'Lava Hot':5}\n",
    "\n",
    "all_data['ord_1'] = all_data['ord_1'].map(ord1dict)\n",
    "all_data['ord_2'] = all_data['ord_2'].map(ord2dict)\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ord_345 = ['ord_3', 'ord_4', 'ord_5']\n",
    "\n",
    "ord_encoder = OrdinalEncoder() # OrdinalEncoder 객체 생성\n",
    "# ordinal 인코딩 적용\n",
    "all_data[ord_345] = ord_encoder.fit_transform(all_data[ord_345])\n",
    "\n",
    "# 피처별 인코딩 순서 출력\n",
    "for feature, categories in zip(ord_345, ord_encoder.categories_):\n",
    "    print(feature)\n",
    "    print(categories)\n",
    "    \n",
    "nom_features = ['nom_' + str(i) for i in range(10)] # 명목형 피처\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot_encoder = OneHotEncoder() # OneHotEncoder 객체 생성\n",
    "# 원-핫 인코딩 적용\n",
    "encoded_nom_matrix = onehot_encoder.fit_transform(all_data[nom_features])\n",
    "\n",
    "encoded_nom_matrix\n",
    "\n",
    "all_data = all_data.drop(nom_features, axis=1) # 기존 명목형 피처 삭제\n",
    "\n",
    "date_features  = ['day', 'month'] # 날짜 피처\n",
    "\n",
    "# 원-핫 인코딩 적용\n",
    "encoded_date_matrix = onehot_encoder.fit_transform(all_data[date_features])\n",
    "\n",
    "all_data = all_data.drop(date_features, axis=1) # 기존 날짜 피처 삭제\n",
    "\n",
    "encoded_date_matrix\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "ord_features = ['ord_' + str(i) for i in range(6)] # 순서형 피처\n",
    "# min-max 정규화\n",
    "all_data[ord_features] = MinMaxScaler().fit_transform(all_data[ord_features])\n",
    "\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "# 인코딩 및 스케일링된 피처 합치기\n",
    "all_data_sprs = sparse.hstack([sparse.csr_matrix(all_data),\n",
    "                               encoded_nom_matrix,\n",
    "                               encoded_date_matrix],\n",
    "                              format='csr')\n",
    "\n",
    "num_train = len(train) # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "X_train = all_data_sprs[:num_train] # 0 ~ num_train - 1행\n",
    "X_test = all_data_sprs[num_train:] # num_train ~ 마지막 행\n",
    "\n",
    "y = train['target']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼파라미터: {'C': 0.125, 'max_iter': 800, 'random_state': 42, 'solver': 'liblinear'}\n",
      "Wall time: 4min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 로지스틱 회귀 모델 생성\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# 하이퍼파라미터 값 목록\n",
    "lr_params = {'C':[0.1, 0.125, 0.2], 'max_iter':[800, 900, 1000], \n",
    "             'solver':['liblinear'], 'random_state':[42]}\n",
    "\n",
    "# 그리드서치 객체 생성\n",
    "gridsearch_logistic_model = GridSearchCV(estimator=logistic_model,\n",
    "                                         param_grid=lr_params,\n",
    "                                         scoring='roc_auc', # 평가지표\n",
    "                                         cv=5)\n",
    "# 그리드서치 수행\n",
    "gridsearch_logistic_model.fit(X_train, y)\n",
    "\n",
    "print('최적 하이퍼파라미터:', gridsearch_logistic_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타깃값 1일 확률 예측\n",
    "y_preds = gridsearch_logistic_model.best_estimator_.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "# 결과 제출 \n",
    "\n",
    "submission['target'] = y_preds\n",
    "\n",
    "if data_path == \"./input/\":\n",
    "    submission.to_csv('./output/'+'submission.csv')\n",
    "else:\n",
    "    submission.to_csv('submission.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
